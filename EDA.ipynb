{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Imports"
      ],
      "metadata": {
        "id": "pkflRywgGROK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "drive.mount('/content/drive',force_remount=True)\n"
      ],
      "metadata": {
        "id": "hCnxb4OHGQgL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data understanding"
      ],
      "metadata": {
        "id": "SPtMKkPTGb3_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## data loading"
      ],
      "metadata": {
        "id": "ozVGPYJEGhVD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Data unique_values"
      ],
      "metadata": {
        "id": "yWNlC3MKGmsT"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BxZdUBngVgt3"
      },
      "outputs": [],
      "source": [
        "#creating unique values count\n",
        "unique_df = pd.DataFrame()\n",
        "for col in df.columns:\n",
        "    unique_df[col] = [df[col].nunique()] # Store only the number of unique values\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Checking data types"
      ],
      "metadata": {
        "id": "LPIvADRrGzrk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "kEccizXNG_QJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.info()"
      ],
      "metadata": {
        "id": "jKQgi96AHAU9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.dtypes"
      ],
      "metadata": {
        "id": "kEEME18bG5Mv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### droping uneccesory columns\n"
      ],
      "metadata": {
        "id": "C19WDTooHEHv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "col_names= ['transaction_id', 'procedure_id', 'trans_group_id', 'trans_group_ar',\n",
        "       'trans_group_en', 'procedure_name_ar', 'procedure_name_en',\n",
        "       'instance_date', 'property_type_id', 'property_type_ar',\n",
        "       'property_type_en', 'property_sub_type_id', 'property_sub_type_ar',\n",
        "       'property_sub_type_en', 'property_usage_ar', 'property_usage_en',\n",
        "       'reg_type_id', 'reg_type_ar', 'reg_type_en', 'area_id', 'area_name_ar',\n",
        "       'area_name_en', 'building_name_ar', 'building_name_en',\n",
        "       'project_number', 'project_name_ar', 'project_name_en',\n",
        "       'master_project_en', 'master_project_ar', 'nearest_landmark_ar',\n",
        "       'nearest_landmark_en', 'nearest_metro_ar', 'nearest_metro_en',\n",
        "       'nearest_mall_ar', 'nearest_mall_en', 'rooms_ar', 'rooms_en',\n",
        "       'has_parking', 'procedure_area', 'actual_worth', 'meter_sale_price',\n",
        "       'rent_value', 'meter_rent_price', 'no_of_parties_role_1',\n",
        "       'no_of_parties_role_2', 'no_of_parties_role_3']\n",
        "\n",
        "numcolumns =  ['transaction_id', 'procedure_id', 'trans_group_id', 'property_type_id',\n",
        "               'property_sub_type_id', 'reg_type_id', 'area_id', 'project_number',\n",
        "               'has_parking', 'actual_worth', 'meter_sale_price',\n",
        "               'no_of_parties_role_1', 'no_of_parties_role_2', 'no_of_parties_role_3']\n",
        "\n",
        "removing_columns =['trans_group_ar', 'procedure_name_ar', 'property_type_ar',\n",
        "                    'property_sub_type_ar', 'property_usage_ar', 'reg_type_ar',\n",
        "                    'area_name_ar', 'building_name_ar', 'project_name_ar',\n",
        "                    'master_project_ar', 'nearest_landmark_ar', 'nearest_metro_ar',\n",
        "                    'nearest_mall_ar', 'rooms_ar']\n"
      ],
      "metadata": {
        "id": "2DiPNzcdG6LF"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df1 =df.drop(columns=removing_columns)\n",
        "df1.shape"
      ],
      "metadata": {
        "id": "kYV28QhKHKJ5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = df1.copy()"
      ],
      "metadata": {
        "id": "uJYje9Z2Iwjh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### null values"
      ],
      "metadata": {
        "id": "SWTph5iYIq5M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "null_df_summary = pd.DataFrame()\n",
        "null_df_summary['null_count']= df.isnull().sum()\n",
        "null_df_summary['null_%'] = (null_df_summary['null_count'] / len(df)) * 100\n",
        "write_to_excel(null_df_summary, sheet_name='null_df_summary')\n",
        "instance_Year = df.groupby(['instance_Year'])[['meter_sale_price']].describe().round(3)\n",
        "write_to_excel(instance_Year, sheet_name='instance_Year')\n",
        "data_info = df.info()\n",
        "write_to_excel(data_info, sheet_name='data_info')"
      ],
      "metadata": {
        "id": "vsDBY33cIucd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#info_df = pd.DataFrame()  # Initialize an empty DataFrame\n",
        "#info_df['columns'] = df.columns\n",
        "#info_df['Datatype'] = df.dtypes\n",
        "#info_df['Non_Null_Count'] = df.count()\n",
        "#info_df['Null_Count'] = df.isnull().sum()\n",
        "#info_df['Unique_Count'] = df.nunique()\n",
        "#= df.min()\n",
        "# info_df['Max_Value'] = df.max()\n",
        "data_summary_df = df['instance_date'].max() # Transpose and assign to a new variable\n",
        "#data_summary_df.to_csv('data_summary.csv', index=True)  # Save to a CSV file"
      ],
      "metadata": {
        "id": "L3w264lrJGye"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "summary = df.describe().round(4)#.to_excel('description.xlsx', sheet_name='Sheet1', index=True)"
      ],
      "metadata": {
        "id": "6qdjAJYsHRdW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data analysis\n"
      ],
      "metadata": {
        "id": "I9_U8J6QHq0c"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Primary focus on **meter_sale_price**"
      ],
      "metadata": {
        "id": "7i_TwXXnHzl8"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "AjmldrR1IQsl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def describe_df(df):\n",
        "  #write_to_excel(summary, sheet_name='Summary')\n",
        "  Summary_df = df.describe().round(4).transpose()\n",
        "  write_to_excel(Summary_df, sheet_name='Summary_df')\n",
        "\n",
        "  year_wise_data = df.groupby(['instance_Year','instance_Month'],dropna = False)[['actual_worth','meter_sale_price']].describe().round(4)\n",
        "  write_to_excel(year_wise_data, sheet_name='Year_wise_data')\n",
        "\n",
        "  month_wise_data = df.groupby(['instance_Month'],dropna = False)[['meter_sale_price']].describe().round(4)\n",
        "  write_to_excel(month_wise_data, sheet_name='Month_wise_data')\n",
        "\n",
        "  property_type = df.groupby(['property_type_en'],dropna = False)[['meter_sale_price']].describe().round(3)\n",
        "  write_to_excel(property_type, sheet_name='property_type')\n",
        "\n",
        "  property_sub_type_en = df.groupby(['property_sub_type_en'],dropna = False)[['meter_sale_price']].describe().round(4)\n",
        "  write_to_excel(property_sub_type_en, sheet_name='property_sub_type_en')\n",
        "\n",
        "  master_project = df.groupby(['master_project_en'],dropna = False)[['meter_sale_price']].describe().round(4)\n",
        "  write_to_excel(master_project, sheet_name='master_project')\n",
        "\n",
        "  project_name = df.groupby(['project_name_en'],dropna = False)[['meter_sale_price']].describe().round(3)\n",
        "  write_to_excel(project_name, sheet_name='project_name')\n",
        "\n",
        "  area_name_en = df.groupby(['area_name_en'],dropna = False)[['meter_sale_price']].describe().round(4)\n",
        "  write_to_excel(area_name_en, sheet_name='area_name_en')\n",
        "\n",
        "  building_name = df.groupby(['building_name_en'],dropna = False)[['meter_sale_price']].describe().round(3)\n",
        "  write_to_excel(building_name, sheet_name='building_name')\n",
        "\n",
        "  nearest_landmark= df.groupby(['nearest_landmark_en'],dropna = False)[['meter_sale_price']].describe().round(4)\n",
        "  write_to_excel(nearest_landmark, sheet_name='nearest_landmark')\n",
        "\n",
        "  nearest_metro_en = df.groupby(['nearest_metro_en'],dropna = False)[['meter_sale_price']].describe().round(4)\n",
        "  write_to_excel(nearest_metro_en, sheet_name='nearest_metro_en')\n",
        "\n",
        "  nearest_mall = df.groupby(['nearest_mall_en'],dropna = False)[['meter_sale_price']].describe().round(3)\n",
        "  write_to_excel(nearest_mall, sheet_name='nearest_mall')\n",
        "\n",
        "  property_usage = df.groupby(['property_usage_en'],dropna = False)[['meter_sale_price']].describe().round(4)\n",
        "  write_to_excel(property_usage, sheet_name='property_usage')\n",
        "\n",
        "  rooms = df.groupby(['rooms_en'],dropna = False)[['meter_sale_price']].describe().round(4)\n",
        "  write_to_excel(rooms, sheet_name='rooms')\n",
        "\n",
        "  trans_group = df.groupby(['trans_group_en'],dropna = False)[['meter_sale_price']].describe().round(3)\n",
        "  write_to_excel(trans_group, sheet_name='trans_group')\n",
        "\n",
        "  reg_type = df.groupby(['reg_type_en'],dropna = False)[['meter_sale_price']].describe().round(3)\n",
        "  write_to_excel(reg_type, sheet_name='reg_type')\n",
        "\n",
        "  has_parking = df.groupby(['has_parking'],dropna = False)[['meter_sale_price']].describe().round(3)\n",
        "  write_to_excel(has_parking, sheet_name='has_parking')\n",
        "\n",
        "  print(\"all excuted Succesfully\")\n",
        "\n",
        "  return 0\n",
        "\n",
        "\n",
        "  #import pandas as pd # Make sure pandas is imported\n",
        "#null_df = pd.DataFrame() # Defining null_df before using it\n",
        "\n",
        "\n",
        "#write_to_excel(df_dtypes, sheet_name='df_dtypes')\n"
      ],
      "metadata": {
        "id": "tnUMlF08IBeh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## modified data"
      ],
      "metadata": {
        "id": "k5oPcJJMM5xv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "q1 = df['meter_sale_price'].quantile(0.25)\n",
        "q3 = df['meter_sale_price'].quantile(0.75)\n",
        "iqr = q3 - q1\n",
        "mlower = q1 - 1.5 * iqr\n",
        "mupper = q3 + 1.5 * iqr\n",
        "\n",
        "pq1 = df['procedure_area'].quantile(0.25)\n",
        "pq3 = df['procedure_area'].quantile(0.75)\n",
        "piqr = pq3 - pq1\n",
        "plower = pq1 - 1.5 * piqr\n",
        "pupper = pq3 + 1.5 * piqr\n",
        "\n",
        "# Apply both conditions directly to the 'df' DataFrame\n",
        "odf_upper = df[(df['meter_sale_price'] > mupper) | (df['procedure_area'] > pupper)] # | (df[df['instance_year'] < \"2020\"])  & df['property_type_en'] = ]]\n",
        "odf_lower = df[(df['meter_sale_price'] < 1) | (df['procedure_area'] < 1)]\n",
        "odf = pd.concat([odf_upper, odf_lower])\n",
        "odf.shape"
      ],
      "metadata": {
        "id": "NHcYPPidM_hB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Odf is the file used for new data file for modeling."
      ],
      "metadata": {
        "id": "gsWAEumhNGC6"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "P2gi1XNXM5TW"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}